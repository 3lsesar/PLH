{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports i definició de les variables d'arxius\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\albert\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deu_trn.txt', 'eng_trn.txt', 'fra_trn.txt', 'ita_trn.txt', 'nld_trn.txt', 'spa_trn.txt']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re #Regexs\n",
    "import os #Acces a fitxers\n",
    "\n",
    "import nltk #Tokenització\n",
    "nltk.download('punkt') #Tokenització\n",
    "\n",
    "import numpy as np #Matriu de confusió\n",
    "import seaborn as sns #Matriu de confusió\n",
    "import matplotlib.pyplot as plt #Matriu de confusió\n",
    "import pandas as pd #Matriu de confusió\n",
    "\n",
    "train_files_list = [f for f in os.listdir('corpora') if re.search(r'_trn\\.txt$', f)]\n",
    "test_files_list = [f for f in os.listdir('corpora') if re.search(r'_tst\\.txt$', f)]\n",
    "\n",
    "print(train_files_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "---\n",
    "\n",
    "· Eliminar digits del text \n",
    "· Convertir tot el text a minuscula\n",
    "· Eliminar caracters especials\n",
    "· Substitueix els espais en blanc continus per un de sol\n",
    "· Concatena totes les frases amb un espai doble al mig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocessing(text):\n",
    "    text = text.lower() # Converteix a minúscules\n",
    "    text = text.strip() # Elimina espais en blanc al principi i al final\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Elimina signes de puntuació\n",
    "    text = re.sub(r'\\d+', '', text) # Elimina números\n",
    "    text = re.sub(r'[^\\S\\n]+', ' ', text) # Elimina espais en blanc sobrants excepte \\n\n",
    "    text = re.sub(r'\\n', '  ', text) # Substitueix \\n per dos espais en blanc\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creació dels trigrames de caracters, amb la seva freqüència\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deu\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'word_tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 37\u001b[0m\n\u001b[0;32m     32\u001b[0m             enclosed_trigrams_wds[language_id] \u001b[38;5;241m=\u001b[39m word_trigrams_finder(text)\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m enclosed_trigrams_ch, enclosed_trigrams_wds\n\u001b[1;32m---> 37\u001b[0m trigram_assigner(train_files_list)\n",
      "Cell \u001b[1;32mIn[4], line 32\u001b[0m, in \u001b[0;36mtrigram_assigner\u001b[1;34m(train_files_list)\u001b[0m\n\u001b[0;32m     29\u001b[0m         text \u001b[38;5;241m=\u001b[39m preprocessing(text)\n\u001b[0;32m     31\u001b[0m         enclosed_trigrams_ch[language_id] \u001b[38;5;241m=\u001b[39m character_trigrams_finder(text)\n\u001b[1;32m---> 32\u001b[0m         enclosed_trigrams_wds[language_id] \u001b[38;5;241m=\u001b[39m word_trigrams_finder(text)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m enclosed_trigrams_ch, enclosed_trigrams_wds\n",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m, in \u001b[0;36mword_trigrams_finder\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_trigrams_finder\u001b[39m(text):\n\u001b[1;32m---> 11\u001b[0m     finder \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mTrigramCollocationFinder\u001b[38;5;241m.\u001b[39mfrom_words(word_tokenize(text))\n\u001b[0;32m     12\u001b[0m     finder\u001b[38;5;241m.\u001b[39mapply_freq_filter(\u001b[38;5;241m5\u001b[39m) \u001b[38;5;66;03m# Filtra els trigrames amb freqüència menor a 5\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     trigrams \u001b[38;5;241m=\u001b[39m finder\u001b[38;5;241m.\u001b[39mngram_fd\u001b[38;5;241m.\u001b[39mitems()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def character_trigrams_finder(text):\n",
    "    finder = nltk.TrigramCollocationFinder.from_words(text)\n",
    "    finder.apply_freq_filter(5) # Filtra els trigrames que apareixen menys de 5 vegades\n",
    "    trigrams = finder.ngram_fd.items()\n",
    "    #trigrams = sorted(trigrams.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def word_trigrams_finder(text):\n",
    "    finder = nltk.TrigramCollocationFinder.from_words(word_tokenize(text))\n",
    "    finder.apply_freq_filter(5) # Filtra els trigrames amb freqüència menor a 5\n",
    "    trigrams = finder.ngram_fd.items()\n",
    "    #trigrams = sorted(trigrams.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return trigrams\n",
    "\n",
    "\n",
    "def trigram_assigner(train_files_list):\n",
    "    \n",
    "    enclosed_trigrams_ch = {}\n",
    "    enclosed_trigrams_wds = {}\n",
    "\n",
    "    for file in train_files_list:\n",
    "        with open('corpora/' + file, 'r') as f:\n",
    "            language_id = file.split('_')[0] # ID de l'idioma\n",
    "            print(language_id)\n",
    "            text = f.read()\n",
    "            text = preprocessing(text)\n",
    "            \n",
    "            enclosed_trigrams_ch[language_id] = character_trigrams_finder(text)\n",
    "            enclosed_trigrams_wds[language_id] = word_trigrams_finder(text)\n",
    "            \n",
    "    return enclosed_trigrams_ch, enclosed_trigrams_wds\n",
    "\n",
    "\n",
    "trigram_assigner(train_files_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
