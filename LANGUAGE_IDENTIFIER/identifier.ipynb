{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports i definició de les variables d'arxius\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re #Regexs\n",
    "import os #Acces a fitxers\n",
    "\n",
    "import nltk #Tokenització\n",
    "nltk.download('punkt') #Tokenització\n",
    "\n",
    "import numpy as np #Matriu de confusió\n",
    "import seaborn as sns #Matriu de confusió\n",
    "import matplotlib.pyplot as plt #Matriu de confusió\n",
    "import sklearn #Matriu de confusió\n",
    "\n",
    "train_files_list = [f for f in os.listdir('corpora') if re.search(r'_trn\\.txt$', f)]\n",
    "test_files_list = [f for f in os.listdir('corpora') if re.search(r'_tst\\.txt$', f)]\n",
    "\n",
    "print(train_files_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "---\n",
    "\n",
    "· Eliminar digits del text \n",
    "· Convertir tot el text a minuscula\n",
    "· Eliminar caracters especials\n",
    "· Substitueix els espais en blanc continus per un de sol\n",
    "· Concatena totes les frases amb un espai doble al mig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocessing(text):\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Elimina signes de puntuació\n",
    "    text = re.sub(r'\\d+', '', text) # Elimina números\n",
    "    text = text.lower() # Converteix a minúscules\n",
    "    text = re.sub(r'[\\s\\n]+', ' ', text) # Elimina espais en blanc sobrants excepte \\n\n",
    "    text = re.sub(r' +', ' ', text) # Elimina espais en blanc llargs\n",
    "    text = re.sub(r'\\n', '  ', text) # Substitueix \\n per dos espais en blanc\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creació dels trigrames amb la seva freqüència\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creació de les funcions bàsiques per a la generació i assignació dels trigrames de caracters i bigrames de paraules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructura de dades de les variables dels trigrames\n",
    "# {key: id_idioma value: \n",
    "#   {key: trigrama, value: freqüència}}\n",
    "\n",
    "# Reb un text i retorna un diccionari amb els trigrames i les seves freqüències\n",
    "\n",
    "def character_trigrams_finder(text, flag='trn'):\n",
    "    finder = nltk.TrigramCollocationFinder.from_words(text)\n",
    "    if flag == 'trn':\n",
    "        finder.apply_freq_filter(5)\n",
    "    trigrams = finder.ngram_fd.items()\n",
    "    trigrams_dict = {trigram: count for trigram, count in trigrams}\n",
    "    \n",
    "    return trigrams_dict\n",
    "\n",
    "def word_trigrams_finder(text):\n",
    "    finder = nltk.BigramCollocationFinder.from_words(nltk.word_tokenize(text))\n",
    "    trigrams = finder.ngram_fd.items()\n",
    "    trigrams_dict = {trigram: count for trigram, count in trigrams}\n",
    "\n",
    "    return trigrams_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reb una llista amb els noms dels fitxers, guarda els textos dels arxius indexats, \n",
    "# Els preprocessa i en extreu els trigrames retornant un diccionari\n",
    "\n",
    "def trigram_assigner_ch(train_files_list):\n",
    "    \n",
    "    enclosed_trigrams_ch = {}\n",
    "\n",
    "    for file in train_files_list:\n",
    "        with open('corpora/' + file, 'r', encoding='utf-8') as f:\n",
    "            language_id = file.split('_')[0] # ID de l'idioma\n",
    "            print(language_id)\n",
    "            text = f.read()\n",
    "            text = preprocessing(text)\n",
    "            enclosed_trigrams_ch[language_id] = character_trigrams_finder(text)\n",
    "\n",
    "    return enclosed_trigrams_ch\n",
    "\n",
    "def trigram_assigner_wds(train_files_list):\n",
    "    enclosed_trigrams_wds = {}\n",
    "    for file in train_files_list:\n",
    "        with open('corpora/' + file, 'r', encoding='utf-8') as f:\n",
    "            language_id = file.split('_')[0] # ID de l'idioma\n",
    "            print(language_id)\n",
    "            text = f.read()\n",
    "            text = preprocessing(text)\n",
    "            enclosed_trigrams_wds[language_id] = word_trigrams_finder(text)\n",
    "            \n",
    "    return enclosed_trigrams_wds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams_ch = trigram_assigner_ch(train_files_list)\n",
    "print()\n",
    "trigrams_wds = trigram_assigner_wds(train_files_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separa el test per oracions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_files_separator(test_files_list):\n",
    "    test_files = {}\n",
    "    for file in test_files_list:\n",
    "        with open('corpora/' + file, 'r', encoding='utf-8') as f:\n",
    "            language_id = file.split('_')[0] # ID de l'idioma\n",
    "            print(language_id)\n",
    "            text = f.read()\n",
    "            test_files[language_id] = nltk.sent_tokenize(text)\n",
    "            for i in range(len(test_files[language_id])):\n",
    "                test_files[language_id][i] = preprocessing(test_files[language_id][i])\n",
    "    return test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = test_files_separator(test_files_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elimina les oracions amb menys de 3 caracters\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionari de totes les frases de cada idioma dels fitxers de test\n",
    "# Key: Id idioma, Value: Llista de frases\n",
    "# Elimina les frases amb menys de 3 caràcters\n",
    "for idioma in trigrams_ch:\n",
    "    test_files[idioma] =  [elemento for elemento in test_files[idioma] if len(elemento) >= 3]\n",
    "    \n",
    "print()\n",
    "\n",
    "for idioma in trigrams_wds:\n",
    "    test_files[idioma] =  [elemento for elemento in test_files[idioma] if len(elemento) >= 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcio de suavitzat\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sumatori del logaritme de (les aparicions del trigrama en el train + alpha / trigrames que apareixen en el train + alpha * vocabulari(beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reb com a parametres una oracio i un flag que pot ser 'chars' o 'words' i un alpha que per defecte es 0.5\n",
    "def suavitzat(oracio, flag = 'chars', prints = False, alpha = 0.5):\n",
    "    #chars es un dict, trigrams_ch es un dict\n",
    "    if flag == 'chars':\n",
    "        chars = character_trigrams_finder(oracio, 'test')\n",
    "    elif flag == 'words':\n",
    "        chars = word_trigrams_finder(oracio)\n",
    "    probabilities = {}\n",
    "    for idioma in trigrams_ch: #iterem per idioma\n",
    "        prob = 0\n",
    "        for trigram in chars.keys(): #Agafa un trigrama concret de la frase\n",
    "            if flag == 'chars':      #Busca el nombre d'aparicions d'aquest trigrama concret al diccionari\n",
    "                aparicions = trigrams_ch[idioma].get(trigram, 0)\n",
    "                beta = (len(trigrams_ch[idioma]))\n",
    "            if flag == 'words':\n",
    "                aparicions = trigrams_wds[idioma].get(trigram, 0)\n",
    "                beta = (len(trigrams_ch[idioma])*3)\n",
    "            prob_trigrama = ((aparicions + alpha) / ((len(trigrams_ch[idioma])) + alpha * beta)) # la nostra beta (trigrames totals del idioma) es el nombre de trigrames totals del train\n",
    "            prob += np.log(prob_trigrama)\n",
    "        probabilities[idioma] = prob\n",
    "    sorted_prob = sorted(probabilities.items(), key=lambda x:x[1], reverse=True)\n",
    "    sort_prob = dict(sorted_prob)\n",
    "    if prints == True:\n",
    "        print(oracio, '\\n')\n",
    "        print (' L\\'idioma de la oració és:', list(sort_prob.keys())[0])\n",
    "        print ('\\n', sort_prob)\n",
    "    return list(sort_prob.keys())[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug d'una frase concreta qualsevol\n",
    "suavitzat(test_files['eng'][6], 'words', True, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrius de Confusió per paraules i caracters\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executem el 'smoothing' per obtindre les prediccions, les guardem en les llistes, i mitjançant les llibreries importades, es construeixen les dues matrius de confusió amb el count dels cops en que una predicció ha sigut acertada:\n",
    "- Matriu de confusió per caracters\n",
    "- Matriu de confusió per paraules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crida a la funció de 'smoothing' per a cada frase dels fitxers de test, i guarda les prediccions i els valors objectius.\n",
    "\n",
    "prediccio_words = []\n",
    "valor_obj_words = []\n",
    "\n",
    "prediccio_chars = []\n",
    "valor_obj_chars = []\n",
    "\n",
    "for idioma in test_files:\n",
    "    for oracio in test_files[idioma]:\n",
    "        valor_obj_chars.append(idioma)\n",
    "        valor_obj_words.append(idioma)\n",
    "        prediccio_chars.append(suavitzat(oracio, 'chars', False, 0.5))\n",
    "        prediccio_words.append(suavitzat(oracio, 'words', False, 0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriu_confusio_chars = sklearn.metrics.confusion_matrix(valor_obj_chars, prediccio_chars)\n",
    "matriu_confusio_words = sklearn.metrics.confusion_matrix(valor_obj_words, prediccio_words)\n",
    "\n",
    "labels = ['deu', 'eng', 'fra', 'ita', 'nld', 'spa']\n",
    "\n",
    "print(\"Matriu de Confusió de Caracters:\")\n",
    "print(matriu_confusio_chars)\n",
    "\n",
    "### Matriu de confusió de caracters\n",
    "sns.heatmap(matriu_confusio_chars, annot=True, annot_kws={\"size\": 12}, fmt='g', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriu de Confusió de Caracters')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Matriu de Confusió de Paraules:\")\n",
    "print(matriu_confusio_words)\n",
    "\n",
    "\n",
    "### Matriu de confusió de paraules\n",
    "sns.heatmap(matriu_confusio_words, annot=True, annot_kws={\"size\": 12}, fmt='g', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriu de Confusió de Paraules')\n",
    "plt.tight_layout\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrius de confusió amb el 'accuracy'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculem el 'accuracy general de les prediccions, tant per caracters com per paraules, i construim les seves respectives matrius de confusió mostrant aquest cop el percentatge d'èxit:\n",
    "- Matriu de confusió amb 'accuracy' dels caracters\n",
    "- Matriu de confusió amb 'accuracy' de les paraules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#calculem la accuracy\n",
    "accuracy_chars = sklearn.metrics.accuracy_score(valor_obj_chars, prediccio_chars)\n",
    "accuracy_words = sklearn.metrics.accuracy_score(valor_obj_words, prediccio_words)\n",
    "print(\"Accuracy for chars: \", accuracy_chars)\n",
    "print(\"Accuracy for words: \", accuracy_words)\n",
    "\n",
    "#fem la matriu de confusio amb la accuracy\n",
    "matriu_confusio_chars = np.round(matriu_confusio_chars / matriu_confusio_chars.sum(axis=1)[:, np.newaxis] * 100, decimals=29)\n",
    "matriu_confusio_words = np.round(matriu_confusio_words / matriu_confusio_words.sum(axis=1)[:, np.newaxis] * 100, decimals=29)\n",
    "\n",
    "### Matriu de confusió de caracters amb accuracy\n",
    "print(\"\\nMatriu de confusió de caracters amb accuracy:\")\n",
    "sns.heatmap(matriu_confusio_chars, annot=True, annot_kws={\"size\": 14}, fmt='.2f', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriu de Confusió de Caracters')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### Matriu de confusió de paraules amb accuracy\n",
    "print(\"\\nMatriu de confusió de paraules amb accuracy:\")\n",
    "sns.heatmap(matriu_confusio_words, annot=True, annot_kws={\"size\": 14}, fmt='.2f', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriu de Confusió de Paraules')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
